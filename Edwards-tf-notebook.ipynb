{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC 478 Machine Learning\n",
    "\n",
    "\n",
    "## Getting Started with Tensorflow, Keras, and Tensorboard\n",
    "\n",
    "### Instructor: Fereydoon Vafaei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sam Edwards VZ13212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook helps you get started with Tensorflow/Keras API. This notebook assumes you have installed Tensorflow 2.<br>\n",
    "If you have not installed Tensorflow 2 or have installed previous versions of Tensorflow, you need to [install Tensorflow 2](https://www.tensorflow.org/install) before proceeding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Installation Verification](#Installation-Verification)\n",
    "* [A Simple Regression NN](#A-One-Layer-One-Neuron-Regression-Neural-Network-using-Tensorflow/Keras)\n",
    "* [A Multi-layer NN on MNIST Dataset](#A-Multi-Layer-NN-for-Multi-Class-Classification-on-MNIST-Dataset)\n",
    "* [Eager Execution in Tensorflow-2](#Eager-Execution-in-Tensorflow-2)\n",
    "* [Creating the model using the Sequential API](#Creating-the-model-using-the-Sequential-API)\n",
    "* [Fashion MNIST Dataset](#Fashion-MNIST-Dataset)\n",
    "* [Using Code Examples from keras.io](#Using-Code-Examples-from-keras.io)\n",
    "* [California House Pricing](#California-House-Pricing)\n",
    "* [Callbacks](#Callbacks)\n",
    "* [Tensorboard](#Tensorboard)\n",
    "* [Exercise-1](#Exercise-1)\n",
    "* [Exercise-2](#Exercise-2)\n",
    "* [References](#References)\n",
    "* [Grading and Submission](#Grading-and-Submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is one of the most popular ML/DL frameworks. Watch this video first:\n",
    "\n",
    "https://www.youtube.com/watch?v=744f60NyAgc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Very Important Note**:\n",
    "\n",
    "**RUN ALL CELLS REQUIREMENT**: You must run all cells to get the outputs and then attempt exercises. Otherwise, if any cell is not run with the correct output, your notebook gets ZERO even if you've completed the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your tf version should be 2.0.0 or higher\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A One-Layer One-Neuron Regression Neural Network using Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first example is a regression NN with only one layer and one neuron to recognize the pattern of a sequence of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 5.8538\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7871\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9442\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.2774\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.7492\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.3301\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9970\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.7316\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5194\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3493\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2123\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1014\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0111\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9371\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.8760\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8250\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7822\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.7457\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7144\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6871\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6630\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6416\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6223\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6046\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5884\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5733\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5592\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5459\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5332\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5211\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5095\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4983\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4875\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4771\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4669\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4571\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4475\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4381\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4290\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4201\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4113\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4028\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3945\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3864\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.3784\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.3706\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3630\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3555\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3482\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3410\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3340\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3271\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.3204\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.3138\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.3074\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3011\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2949\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2888\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2829\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2771\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2714\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2658\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2603\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2550\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2498\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2446\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2396\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2347\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2299\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2251\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2205\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2160\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2116\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2072\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2029\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1988\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1947\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1907\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1868\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1829\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1792\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1755\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1719\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1684\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1649\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1615\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1582\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1550\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1518\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1487\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1456\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1426\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1397\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1368\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1340\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1313\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1286\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1259\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1233\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1208\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1183\n",
      "Epoch 102/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 999us/step - loss: 0.1159\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1135\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1112\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1089\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1067\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1045\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1023\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1002\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0982\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0961\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0942\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0922\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0903\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0885\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0867\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0849\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0831\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0814\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0798\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0781\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0765\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0749\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0734\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0719\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0704\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0690\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0676\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0662\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0648\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0635\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0622\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0609\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0596\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0584\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0572\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0560\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0549\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0538\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0527\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0516\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0505\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0495\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0485\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0475\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0465\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0455\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0446\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0437\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0428\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0419\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0411\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0402\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0394\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0386\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0378\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0370\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0362\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0355\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0348\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0341\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0334\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0327\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0320\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0313\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0307\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0301\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0295\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0288\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0283\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0277\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0271\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0265\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0260\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0255\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0249\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0239\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0234\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0230\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0220\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0203\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0199\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0194\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0190\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0183\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0172\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0168\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0165\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0161\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0158\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0155\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0152\n",
      "Epoch 201/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0134\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0131\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0128\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0126\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0123\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0121\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0118\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0116\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0113\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0111\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0109\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0107\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0104\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0102\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0092\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0087\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0085\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0083\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0081\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0080\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0078\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0076\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0075\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0073\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0072\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0070\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0069\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0067\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0066\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0065\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0063\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0062\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0061\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0060\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0058\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0057\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0056\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0054\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0053\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0052\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0050\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0048\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0047\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0046\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0045\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0045\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0044\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0043\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0042\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0040\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0039\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0038\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0037\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0035\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0034\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0033\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0033\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0032\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0031\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0030\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0029\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0027\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0027\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0026\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0025\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0024\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0023\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0022\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0021\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0020\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0020\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0019\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 999us/step - loss: 0.0019\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0018\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0015\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0015\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0014\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0013\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0013\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0013\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0012\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0012\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0012\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0011\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0010\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9979e-04\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7925e-04\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.5914e-04\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.3944e-04\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.2014e-04\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.0124e-04\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8273e-04\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 746us/step - loss: 8.6460e-04\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.4684e-04\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2944e-04\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.1240e-04\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.9572e-04\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7937e-04\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6336e-04\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.4768e-04\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.3232e-04\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1728e-04\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.0255e-04\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8812e-04\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.7398e-04\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6014e-04\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.4658e-04\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3330e-04\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2029e-04\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0755e-04\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9507e-04\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8285e-04\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7088e-04\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5915e-04\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4766e-04\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.3641e-04\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.2539e-04\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1460e-04\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0403e-04\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9368e-04\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8354e-04\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7361e-04\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6388e-04\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5435e-04\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4502e-04\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3588e-04\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.2692e-04\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1815e-04\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.0956e-04\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.0115e-04\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9291e-04\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8484e-04\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7693e-04\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6920e-04\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.6161e-04\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5418e-04\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4691e-04\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.3978e-04\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3280e-04\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.2597e-04\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1927e-04\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1271e-04\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0629e-04\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.0000e-04\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.9384e-04\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8780e-04\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8189e-04\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7610e-04\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.7043e-04\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.6488e-04\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5943e-04\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.5410e-04\n",
      "Epoch 398/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 999us/step - loss: 2.4888e-04\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.4377e-04\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3877e-04\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3386e-04\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.2906e-04\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2435e-04\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1974e-04\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.1523e-04\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1081e-04\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0648e-04\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0224e-04\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9808e-04\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9401e-04\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9003e-04\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8612e-04\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8230e-04\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7856e-04\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.7489e-04\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.7130e-04\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6778e-04\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6433e-04\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6096e-04\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5765e-04\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5441e-04\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5124e-04\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4813e-04\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4509e-04\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4211e-04\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.3919e-04\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3633e-04\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3353e-04\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3079e-04\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2810e-04\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2547e-04\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2289e-04\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2037e-04\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1790e-04\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1548e-04\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1310e-04\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1078e-04\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0851e-04\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0628e-04\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0409e-04\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0196e-04\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.9860e-05\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7809e-05\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5800e-05\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.3833e-05\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.1906e-05\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0019e-05\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8169e-05\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6358e-05\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.4584e-05\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2848e-05\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.1145e-05\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.9479e-05\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7847e-05\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.6247e-05\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.4682e-05\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.3147e-05\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1646e-05\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.0174e-05\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8733e-05\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7320e-05\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.5937e-05\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4582e-05\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3256e-05\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1957e-05\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0685e-05\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9438e-05\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8217e-05\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7021e-05\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5851e-05\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.4703e-05\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.3579e-05\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2479e-05\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1401e-05\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 5.0346e-05\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9311e-05\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8299e-05\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7306e-05\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6334e-05\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.5383e-05\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.4450e-05\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.3537e-05\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2642e-05\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1767e-05\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.0909e-05\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.0069e-05\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9247e-05\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8440e-05\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7650e-05\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6876e-05\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6120e-05\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5377e-05\n",
      "Epoch 493/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 3.4651e-05\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3939e-05\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3242e-05\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.2558e-05\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.1890e-05\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.1234e-05\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0593e-05\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.9965e-05\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.9349e-05\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.8747e-05\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.8156e-05\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7578e-05\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.7012e-05\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.6457e-05\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5914e-05\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.5382e-05\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4860e-05\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4349e-05\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3849e-05\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3359e-05\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2879e-05\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2409e-05\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1949e-05\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1498e-05\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1057e-05\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0624e-05\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.0200e-05\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9786e-05\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9379e-05\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8981e-05\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8591e-05\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8209e-05\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7835e-05\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7469e-05\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.7110e-05\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6759e-05\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6415e-05\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6077e-05\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5747e-05\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5423e-05\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5107e-05\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4797e-05\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4492e-05\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4195e-05\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.3904e-05\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3618e-05\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3338e-05\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3064e-05\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2796e-05\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2533e-05\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2276e-05\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2024e-05\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1776e-05\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1534e-05\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1297e-05\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1066e-05\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0839e-05\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0616e-05\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0397e-05\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0184e-05\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9751e-06\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7700e-06\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.5693e-06\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.3725e-06\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1801e-06\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9915e-06\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8071e-06\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6262e-06\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4490e-06\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.2751e-06\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.1053e-06\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.9388e-06\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7760e-06\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.6160e-06\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.4597e-06\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3066e-06\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1565e-06\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.0096e-06\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.8655e-06\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.7244e-06\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.5863e-06\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4512e-06\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3185e-06\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.1885e-06\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.0617e-06\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9371e-06\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.8151e-06\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6956e-06\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5788e-06\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.4641e-06\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3521e-06\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2421e-06\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1342e-06\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0287e-06\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9255e-06\n",
      "Epoch 588/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8244e-06\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7251e-06\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.6281e-06\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5330e-06\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4397e-06\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3485e-06\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2593e-06\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.1721e-06\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0862e-06\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0020e-06\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.9198e-06\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8395e-06\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7607e-06\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.6831e-06\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6077e-06\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5337e-06\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4610e-06\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3900e-06\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3201e-06\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2519e-06\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.1851e-06\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.1195e-06\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0557e-06\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9928e-06\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.9315e-06\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8712e-06\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.8120e-06\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.7544e-06\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.6977e-06\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.6422e-06\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5879e-06\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5348e-06\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4828e-06\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.4318e-06\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.3817e-06\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3328e-06\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2849e-06\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2379e-06\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1920e-06\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1470e-06\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.1030e-06\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0598e-06\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0175e-06\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9759e-06\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.9353e-06\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8956e-06\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8568e-06\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8186e-06\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7811e-06\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.7447e-06\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7088e-06\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.6738e-06\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6395e-06\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6058e-06\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5728e-06\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5403e-06\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5087e-06\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.4775e-06\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4472e-06\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4174e-06\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.3884e-06\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3599e-06\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3318e-06\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3044e-06\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2778e-06\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2515e-06\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2259e-06\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2007e-06\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1759e-06\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1518e-06\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1281e-06\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1050e-06\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0822e-06\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0601e-06\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0384e-06\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0169e-06\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.9612e-07\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7563e-07\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5556e-07\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.3597e-07\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.1666e-07\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 8.9795e-07\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7949e-07\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6147e-07\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4378e-07\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 8.2644e-07\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.0927e-07\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.9272e-07\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7650e-07\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6051e-07\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.4490e-07\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2957e-07\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1465e-07\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.0001e-07\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8560e-07\n",
      "Epoch 683/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7150e-07\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.5769e-07\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4425e-07\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3091e-07\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.1797e-07\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0533e-07\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.9293e-07\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8076e-07\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.6882e-07\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5707e-07\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.4569e-07\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3446e-07\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2339e-07\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1263e-07\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.0212e-07\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9189e-07\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8169e-07\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7189e-07\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6216e-07\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5265e-07\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4335e-07\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3418e-07\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2530e-07\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1659e-07\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.0805e-07\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9971e-07\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9151e-07\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8338e-07\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7553e-07\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.6776e-07\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.6031e-07\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.5282e-07\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4559e-07\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3855e-07\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3152e-07\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2480e-07\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.1805e-07\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1158e-07\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.0512e-07\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9894e-07\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9275e-07\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.8673e-07\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8083e-07\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7508e-07\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.6941e-07\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6390e-07\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5849e-07\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5321e-07\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4797e-07\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.4293e-07\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3789e-07\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.3307e-07\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2826e-07\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.2352e-07\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1892e-07\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1448e-07\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1009e-07\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.0573e-07\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0155e-07\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9735e-07\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9332e-07\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8939e-07\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8551e-07\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.8166e-07\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.7794e-07\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7421e-07\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.7067e-07\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6713e-07\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6375e-07\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.6038e-07\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5703e-07\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5381e-07\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5064e-07\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4756e-07\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4454e-07\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.4162e-07\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3871e-07\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3588e-07\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3302e-07\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.3027e-07\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2761e-07\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2498e-07\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2246e-07\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1993e-07\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1749e-07\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1502e-07\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1264e-07\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1035e-07\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0810e-07\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0593e-07\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0373e-07\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0158e-07\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9509e-08\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.7469e-08\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.5450e-08\n",
      "Epoch 778/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 999us/step - loss: 9.3509e-08\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.1578e-08\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9704e-08\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 8.7850e-08\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.6068e-08\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.4301e-08\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 8.2530e-08\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 8.0828e-08\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.9184e-08\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7570e-08\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5978e-08\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.4412e-08\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2870e-08\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.1399e-08\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9933e-08\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.8465e-08\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7061e-08\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5711e-08\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4338e-08\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.3041e-08\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1734e-08\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0455e-08\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9206e-08\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8004e-08\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6829e-08\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.5657e-08\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.4505e-08\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3383e-08\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2276e-08\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1210e-08\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0167e-08\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9128e-08\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8121e-08\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.7156e-08\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.6163e-08\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.5223e-08\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.4301e-08\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.3393e-08\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2495e-08\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.1612e-08\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0777e-08\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9949e-08\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.9137e-08\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8320e-08\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7529e-08\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6782e-08\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6012e-08\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.5286e-08\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4584e-08\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3839e-08\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3147e-08\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2454e-08\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1820e-08\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1153e-08\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0521e-08\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.9886e-08\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9270e-08\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.8667e-08\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8098e-08\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7507e-08\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6938e-08\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.6398e-08\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5857e-08\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5332e-08\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4822e-08\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4308e-08\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3799e-08\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.3315e-08\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.2820e-08\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.2346e-08\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1889e-08\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1444e-08\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0997e-08\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.0569e-08\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.0174e-08\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9749e-08\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9333e-08\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8951e-08\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8575e-08\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8191e-08\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.7801e-08\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7438e-08\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7086e-08\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6738e-08\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6381e-08\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6044e-08\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5727e-08\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5394e-08\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5071e-08\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4770e-08\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4472e-08\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.4170e-08\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3886e-08\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3593e-08\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3308e-08\n",
      "Epoch 873/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3056e-08\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2795e-08\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2522e-08\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2261e-08\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2016e-08\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1777e-08\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1536e-08\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1304e-08\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1075e-08\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0848e-08\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0624e-08\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0401e-08\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0188e-08\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9731e-09\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7579e-09\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.5654e-09\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3634e-09\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1801e-09\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.9822e-09\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7925e-09\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6134e-09\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.4512e-09\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2626e-09\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 8.1071e-09\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.9407e-09\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.7703e-09\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.6251e-09\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.4586e-09\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.3164e-09\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1581e-09\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0137e-09\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8810e-09\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.7419e-09\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6064e-09\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4718e-09\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.3424e-09\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2138e-09\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.0837e-09\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.9598e-09\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8352e-09\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7166e-09\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5938e-09\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4751e-09\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.3648e-09\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.2613e-09\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.1462e-09\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0445e-09\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9389e-09\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8291e-09\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7414e-09\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6351e-09\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5433e-09\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4507e-09\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3707e-09\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2783e-09\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1882e-09\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1052e-09\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0169e-09\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9423e-09\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8624e-09\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7797e-09\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.7074e-09\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.6358e-09\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.5516e-09\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4780e-09\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.4147e-09\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3463e-09\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.2742e-09\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2126e-09\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.1464e-09\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.0762e-09\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0148e-09\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.9538e-09\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8970e-09\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8372e-09\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7815e-09\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.7230e-09\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6684e-09\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6110e-09\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.5576e-09\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5046e-09\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4593e-09\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4102e-09\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3574e-09\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.3162e-09\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.2658e-09\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.2143e-09\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1681e-09\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1193e-09\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0779e-09\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0327e-09\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9933e-09\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9479e-09\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9097e-09\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.8738e-09\n",
      "Epoch 968/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8316e-09\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.7933e-09\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7592e-09\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7165e-09\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6867e-09\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.6475e-09\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6208e-09\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5873e-09\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.5542e-09\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5235e-09\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.4931e-09\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.4594e-09\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4296e-09\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3983e-09\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3686e-09\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3438e-09\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3161e-09\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2894e-09\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2655e-09\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2444e-09\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2161e-09\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1906e-09\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1676e-09\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1417e-09\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1169e-09\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0947e-09\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0771e-09\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0574e-09\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0333e-09\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0162e-09\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9278e-10\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.7488e-10\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.5515e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x130ab050e20>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple linear regression NN with one layer\n",
    "\n",
    "# build a one-layer one-neuron NN\n",
    "layer_1 = keras.layers.Dense(units=1, input_shape=[1])\n",
    "model = tf.keras.Sequential([layer_1])\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error') # 'mse'\n",
    "\n",
    "# data: y = 2x - 1\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float) \n",
    "\n",
    "# train NN\n",
    "model.fit(xs, ys, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred when x=10.0 [[18.999907]]\n",
      "Parameters: [array([[1.9999866]], dtype=float32), array([-0.9999596], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# using NN, predict y when x=10.0\n",
    "print(\"y_pred when x=10.0\", model.predict([10.0]))\n",
    "\n",
    "print(\"Parameters: {}\".format(layer_1.get_weights()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Multi-Layer NN for Multi-Class Classification on MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). Convert the samples from integers to floating-point numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.14901961, 0.74901961, 0.54117647, 0.09411765, 0.09411765,\n",
       "        0.42352941, 0.54117647, 0.13333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2745098 , 0.98823529, 0.98823529, 0.99215686, 0.98823529,\n",
       "        0.98823529, 0.98823529, 0.98823529, 0.63529412, 0.34509804,\n",
       "        0.05098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2       , 0.94117647, 0.98823529, 0.99215686, 0.94117647,\n",
       "        0.71764706, 0.71764706, 0.96470588, 0.99215686, 0.98823529,\n",
       "        0.79215686, 0.55686275, 0.02745098, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.14509804, 0.38431373, 0.82745098, 0.80784314,\n",
       "        0.        , 0.        , 0.16470588, 0.42745098, 0.69411765,\n",
       "        0.98823529, 0.98823529, 0.82745098, 0.16862745, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05098039, 0.07058824,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "        0.21176471, 0.70196078, 0.98823529, 0.8627451 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16862745, 0.94509804, 1.        , 0.36078431,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.90196078, 0.99215686, 0.36078431,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26666667, 0.96470588, 0.96862745, 0.2627451 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.5254902 , 0.98823529, 0.36862745, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.45490196, 0.97254902, 0.78431373, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05098039, 0.38039216,\n",
       "        0.87058824, 0.75294118, 0.04313725, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.14901961, 0.38823529, 0.81568627, 0.89019608,\n",
       "        0.68235294, 0.06666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.81176471, 0.98823529, 0.92941176, 0.34509804,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.31372549, 0.79215686, 0.99215686, 0.95686275,\n",
       "        0.81176471, 0.31372549, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04313725, 0.37647059, 0.98823529,\n",
       "        0.98823529, 0.95686275, 0.28627451, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
       "        0.78039216, 0.97647059, 0.99215686, 0.50196078, 0.03529412,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4627451 , 0.97254902, 0.99215686, 0.44313725,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.45098039, 0.99215686, 0.94117647,\n",
       "        0.19607843, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.99215686, 0.98823529,\n",
       "        0.27058824, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.99215686, 0.90588235,\n",
       "        0.14509804, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a multi-layer NN for multi-class classification\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer\n",
    "  tf.keras.layers.Dense(128, activation='relu'), # hidden layer with 128 neurons\n",
    "  tf.keras.layers.Dropout(0.2), # dropout is a regularization technique\n",
    "  tf.keras.layers.Dense(10, activation='softmax')]) # output layer has 10 neurons and softmax activation function\n",
    "\n",
    "# compile model for multi-class classification\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # loss='SparseCategoricalCrossentropy'\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use `loss='sparse_categorical_crossentropy'` loss function when there are two or more label classes. `tf` expects labels to be provided as integers. If you want to provide labels using `one-hot` representation, use `CategoricalCrossentropy` loss.\n",
    "\n",
    "> Read more about the [`SparseCategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) and [`CategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) in their tf documentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_14 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 652us/step - loss: 0.4800 - accuracy: 0.8586\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 651us/step - loss: 0.1484 - accuracy: 0.9558\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 644us/step - loss: 0.1094 - accuracy: 0.9669\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 640us/step - loss: 0.0857 - accuracy: 0.9737\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 649us/step - loss: 0.0763 - accuracy: 0.9755\n",
      "313/313 - 0s - loss: 0.0718 - accuracy: 0.9769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07183592021465302, 0.9768999814987183]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train NN\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# test NN\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image classifier is now trained to ~98% accuracy on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eager Execution in Tensorflow 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2 has this new capability of [\"Eager Execution\"](https://www.tensorflow.org/guide/eager) which makes it more convenient to work with tensors and graph computations. See examples below and compare it with chapter 9 of the 1st edition which uses Session() and Run() to execute these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.Variable(4, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'x:0' shape=() dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'y:0' shape=() dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(x.numpy())\n",
    "print(y.numpy())\n",
    "print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets review the steps in building a neural network! Here is a classification MLP with two hidden\n",
    "layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a NN for MNIST\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) # the input layer\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) # the first hidden layer with 300 neurons\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) # the 2nd hidden layer with 100 neurons\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) # the output layer: it's a 10-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets go through this code line by line:\n",
    "- The first line creates a Sequential model. This is the simplest kind of Keras model for neural networks that are just composed of a single stack of layers connected sequentially. This is called the Sequential API.\n",
    "\n",
    "- Next, we build the first layer and add it to the model. It is a Flatten layer whose role is to convert each input image into a 1D array: if it receives input data X , it computes `X.reshape(-1, 1)`. This layer does not have any parameters; it is just there to do some simple preprocessing. Since it is the first layer in the model, you should specify the `input_shape` , which doesnt include the batch size, only the shape of the instances. Alternatively, you could add a `keras.layers.InputLayer` as the first layer, setting `input_shape=[28,28]`\n",
    "\n",
    "- Next we add a Dense hidden layer with 300 neurons. It will use the ReLU activation function. Each Dense layer manages its own weight matrix, containing all the connection weights between the neurons and their inputs. It also manages a vector of bias terms (one per neuron). When it receives some input data, it computes Equation 10-2.\n",
    "\n",
    "$$h_{\\mathbf{W}, \\mathbf{b}}(\\mathbf{X}) = \\phi (\\mathbf{X} \\mathbf{W} + \\mathbf{b})$$\n",
    "\n",
    "- Then we add a second Dense hidden layer with 100 neurons, also using the ReLU activation function.\n",
    "\n",
    "- Finally, we add a Dense output layer with 10 neurons (one per class), using the\n",
    "softmax activation function (because the classes are exclusive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Specifying `activation=\"relu\"` is equivalent to specifying `activation=keras.activations.relu`. Other activation functions are available in the keras.activations package. See https://keras.io/activations/ for the full list.\n",
    "\n",
    "> Instead of adding the layers one by one as we just did, you can pass a list of layers when creating the Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(300, activation=\"relu\"),\n",
    "keras.layers.Dense(100, activation=\"relu\"),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is [another example of image classification](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a multi-class classification NN\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')]) # the output layer has 10 neurons and softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 2s 750us/step - loss: 0.6364 - accuracy: 0.7806 - val_loss: 0.4027 - val_accuracy: 0.8587\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 1s 672us/step - loss: 0.3979 - accuracy: 0.8591 - val_loss: 0.3780 - val_accuracy: 0.8640\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 1s 677us/step - loss: 0.3502 - accuracy: 0.8733 - val_loss: 0.3615 - val_accuracy: 0.8647\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 1s 662us/step - loss: 0.3233 - accuracy: 0.8809 - val_loss: 0.3447 - val_accuracy: 0.8762\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 1s 657us/step - loss: 0.2956 - accuracy: 0.8936 - val_loss: 0.3538 - val_accuracy: 0.8643\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 1s 647us/step - loss: 0.2784 - accuracy: 0.8957 - val_loss: 0.3268 - val_accuracy: 0.8857\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 1s 646us/step - loss: 0.2655 - accuracy: 0.8988 - val_loss: 0.3280 - val_accuracy: 0.8843\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 1s 648us/step - loss: 0.2566 - accuracy: 0.9060 - val_loss: 0.3303 - val_accuracy: 0.8872\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 1s 665us/step - loss: 0.2440 - accuracy: 0.9102 - val_loss: 0.3270 - val_accuracy: 0.8870\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 1s 656us/step - loss: 0.2422 - accuracy: 0.9098 - val_loss: 0.3203 - val_accuracy: 0.8873\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `fit()` method returns a History object containing the training parameters `history.params`, the list of epochs it went through `history.epoch`, and most importantly a dictionary `history.history` containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set (if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 10, 'steps': 1688}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you use this dictionary to create a pandas `DataFrame` and call its `plot()` method, you get the learning curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.3499 - accuracy: 0.8807\n",
      "\n",
      "Test accuracy: 0.8806999921798706\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the warning if any\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.14839156e-06, 1.07108024e-10, 2.30924724e-09, 1.90881881e-12,\n",
       "       6.91991631e-10, 6.47122157e-04, 1.28151740e-07, 9.07818205e-04,\n",
       "       2.41646120e-07, 9.98443544e-01], dtype=float32)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can read more on MNIST fashion example [here](https://www.tensorflow.org/tutorials/keras/classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Code Examples from keras.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code examples documented on keras.io will work fine with `tf.keras`, but you need to change the imports. For example, consider this keras.io code which can't be run on this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-197-61f8579950d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0moutput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "output_layer = Dense(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You must change the imports like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "output_layer = Dense(10)\n",
    "\n",
    "# Or simply use full paths, if you prefer:\n",
    "from tensorflow import keras\n",
    "output_layer = keras.layers.Dense(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full path approach is more verbose, so you can easily see which packages to use, and to avoid confusion between standard classes and custom classes.\n",
    "\n",
    "In production code, the shorter approach is typically preferred. Many people also use `from tensorflow.keras import layers` followed by `layers.Dense(10)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California House Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to build a regression model for Califronia house pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 671us/step - loss: 1.8269 - val_loss: 0.5117\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 492us/step - loss: 0.5308 - val_loss: 0.4324\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.4512 - val_loss: 0.3990\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 484us/step - loss: 0.4241 - val_loss: 0.3857\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.4009 - val_loss: 0.3953\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3982 - val_loss: 0.3817\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.4131 - val_loss: 0.3764\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 489us/step - loss: 0.3824 - val_loss: 0.4360\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3993 - val_loss: 0.3851\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3803 - val_loss: 0.3761\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 507us/step - loss: 0.3733 - val_loss: 0.3665\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3659 - val_loss: 0.3573\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 489us/step - loss: 0.3970 - val_loss: 0.3605\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 484us/step - loss: 0.3736 - val_loss: 0.3645\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3675 - val_loss: 0.3555\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 500us/step - loss: 0.3908 - val_loss: 0.3537\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.4295 - val_loss: 0.3511\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3555 - val_loss: 0.3488\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 500us/step - loss: 0.3563 - val_loss: 0.3474\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.3878 - val_loss: 0.3601\n"
     ]
    }
   ],
   "source": [
    "# build a regression NN\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1) # output layer with 1 neuron and with None activation function because it's regression\n",
    "])\n",
    "\n",
    "# compile NN\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 304us/step - loss: 0.3646\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.798902 ],\n",
       "       [3.2005367],\n",
       "       [1.044264 ]], dtype=float32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if training lasts several hours? This is quite common, especially when training on large datasets.\n",
    "\n",
    "In this case, you should not only save your model at the end of training, but also save **checkpoints** at regular intervals during training, to avoid losing everything if your computer crashes.\n",
    "\n",
    "How can you tell the `fit()` method to save **checkpoints**? Use **callbacks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit()` method accepts a `callbacks` argument that lets you specify a list of objects that Keras will call at the start and end of training, at the start and end of each epoch, and even before and after processing each batch. For example, the `ModelCheckpoint` callback saves checkpoints of your model at regular intervals during training, by default at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if you use a validation set during training, you can set `save_best_only=True` when creating the `ModelCheckpoint` .\n",
    "\n",
    "In this case, it will only save your model when its performance on the validation set is the best so far. This way, you do not need to worry about training for too long and overfitting the training set: simply restore the last model saved after training, and this will be the best model on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is a simple way to implement **early stopping**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create checkpoint\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 688us/step - loss: 2.8745 - val_loss: 0.9362\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.9420 - val_loss: 0.6994\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.7181 - val_loss: 0.6307\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.6522 - val_loss: 0.5953\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.5995 - val_loss: 0.5613\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 500us/step - loss: 0.5820 - val_loss: 0.5397\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 500us/step - loss: 0.5396 - val_loss: 0.5229\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.5431 - val_loss: 0.5077\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.5285 - val_loss: 0.4945\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.5117 - val_loss: 0.4841\n"
     ]
    }
   ],
   "source": [
    "# train with callbacks and validation_data\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 317us/step - loss: 0.5052\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Another way to implement **early stopping** is to simply use the `EarlyStopping` callback. It will interrupt training when it measures no progress on the validation set for a number of epochs (defined by the `patience` argument), and it will optionally roll back to the best model.\n",
    "\n",
    "> You can combine both callbacks to save checkpoints of your model (in case your computer crashes) and interrupt training early when there is no more progress (to avoid wasting time and resources):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 705us/step - loss: 0.5003 - val_loss: 0.4751\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.4853 - val_loss: 0.4669\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.4810 - val_loss: 0.4594\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.4892 - val_loss: 0.4533\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.4722 - val_loss: 0.4488\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.4686 - val_loss: 0.4439\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.4598 - val_loss: 0.4370\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.4350 - val_loss: 0.4370\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.4471 - val_loss: 0.4287\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.4400 - val_loss: 0.4253\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.4470 - val_loss: 0.4221\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.4279 - val_loss: 0.4194\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.4254 - val_loss: 0.4174\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.4169 - val_loss: 0.4141\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.4198 - val_loss: 0.4102\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.4129 - val_loss: 0.4076\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.4364 - val_loss: 0.4044\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.4103 - val_loss: 0.4033\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.4044 - val_loss: 0.4003\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.4063 - val_loss: 0.3998\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.4041 - val_loss: 0.3963\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.4089 - val_loss: 0.3951\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.4000 - val_loss: 0.3946\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.4130 - val_loss: 0.3914\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.4006 - val_loss: 0.3908\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.4011 - val_loss: 0.3881\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3837 - val_loss: 0.3860\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3917 - val_loss: 0.3873\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3961 - val_loss: 0.3832\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3912 - val_loss: 0.3833\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3762 - val_loss: 0.3803\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3967 - val_loss: 0.3793\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3907 - val_loss: 0.3781\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3851 - val_loss: 0.3782\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3798 - val_loss: 0.3755\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.3866 - val_loss: 0.3760\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3848 - val_loss: 0.3750\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3940 - val_loss: 0.3737\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3873 - val_loss: 0.3741\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.3789 - val_loss: 0.3711\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3710 - val_loss: 0.3699\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3673 - val_loss: 0.3690\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3778 - val_loss: 0.3689\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3690 - val_loss: 0.3670\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3668 - val_loss: 0.3673\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3708 - val_loss: 0.3671\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3685 - val_loss: 0.3654\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 525us/step - loss: 0.3615 - val_loss: 0.3646\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3669 - val_loss: 0.3645\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3846 - val_loss: 0.3633\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.3789 - val_loss: 0.3631\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3759 - val_loss: 0.3622\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3664 - val_loss: 0.3614\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3589 - val_loss: 0.3626\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3712 - val_loss: 0.3620\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3749 - val_loss: 0.3625\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3726 - val_loss: 0.3594\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.3891 - val_loss: 0.3595\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3722 - val_loss: 0.3582\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3577 - val_loss: 0.3580\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.3812 - val_loss: 0.3579\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3694 - val_loss: 0.3593\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3799 - val_loss: 0.3566\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3890 - val_loss: 0.3563\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.3646 - val_loss: 0.3550\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3557 - val_loss: 0.3559\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3588 - val_loss: 0.3546\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3514 - val_loss: 0.3534\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3690 - val_loss: 0.3543\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3562 - val_loss: 0.3559\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3638 - val_loss: 0.3521\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3631 - val_loss: 0.3525\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3533 - val_loss: 0.3525\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3698 - val_loss: 0.3513\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3585 - val_loss: 0.3517\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3419 - val_loss: 0.3504\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3434 - val_loss: 0.3525\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3423 - val_loss: 0.3498\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3581 - val_loss: 0.3484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3508 - val_loss: 0.3493\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3478 - val_loss: 0.3482\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3532 - val_loss: 0.3477\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3489 - val_loss: 0.3476\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3411 - val_loss: 0.3463\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.3557 - val_loss: 0.3471\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 536us/step - loss: 0.3513 - val_loss: 0.3454\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.3521 - val_loss: 0.3467\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3491 - val_loss: 0.3446\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.3369 - val_loss: 0.3469\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3486 - val_loss: 0.3446\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3585 - val_loss: 0.3438\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3541 - val_loss: 0.3433\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3426 - val_loss: 0.3435\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3379 - val_loss: 0.3426\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3477 - val_loss: 0.3431\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3470 - val_loss: 0.3426\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.3551 - val_loss: 0.3426\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3422 - val_loss: 0.3416\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3599 - val_loss: 0.3408\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3494 - val_loss: 0.3402\n",
      "162/162 [==============================] - 0s 304us/step - loss: 0.3499\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you need extra control, you can easily write your own custom callbacks. As an example of how to do that, the following custom callback will display the ratio between the validation loss and the training loss during training (e.g., to detect overfitting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 597us/step - loss: 0.3461 - val_loss: 0.3425\n",
      "\n",
      "val/train: 0.99\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neat feature of Tensorflow and Keras is visulaization through Tensorboard. The following code shows how you can visualiza your training using Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3460 - val_loss: 0.3399\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3456 - val_loss: 0.3388\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3449 - val_loss: 0.3387\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.3448 - val_loss: 0.3393\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3440 - val_loss: 0.3384\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3438 - val_loss: 0.3383\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3433 - val_loss: 0.3372\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 525us/step - loss: 0.3429 - val_loss: 0.3389\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.3424 - val_loss: 0.3369\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.3420 - val_loss: 0.3370\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.3414 - val_loss: 0.3367\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3409 - val_loss: 0.3369\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3403 - val_loss: 0.3357\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3402 - val_loss: 0.3353\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.3395 - val_loss: 0.3365\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3394 - val_loss: 0.3351\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3388 - val_loss: 0.3341\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3387 - val_loss: 0.3350\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3387 - val_loss: 0.3336\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3378 - val_loss: 0.3343\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 500us/step - loss: 0.3370 - val_loss: 0.3347\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3370 - val_loss: 0.3321\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 500us/step - loss: 0.3375 - val_loss: 0.3328\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.3359 - val_loss: 0.3314\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3355 - val_loss: 0.3315\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3353 - val_loss: 0.3332\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3347 - val_loss: 0.3303\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 500us/step - loss: 0.3345 - val_loss: 0.3304\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 500us/step - loss: 0.3343 - val_loss: 0.3300\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3338 - val_loss: 0.3299\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard Visualization\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, run the following command at the root of the project directory where `my_logs` has been saved (or from anywhere else, as long as you point to the appropriate log directory):\n",
    "\n",
    "> `$ tensorboard --logdir=./my_logs --port=6006`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> And finally, once the server is up, you can open a web browser and go to:\n",
    "\n",
    "> http://localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-1 has 10 points**.\n",
    "\n",
    "In this exercise you'll try to build a neural network that predicts the price of a house according to a simple formula.\n",
    "\n",
    "- Imagine if house pricing was as easy as a house costs 50k + 50k per bedroom, so that a 1 bedroom house costs 100k, a 2 bedroom house costs 150k etc.\n",
    "\n",
    "- How would you create a neural network that learns this relationship so that it would predict a 7 bedroom house as costing close to 400k etc.\n",
    "\n",
    "**Hint**: Your network might work better if you scale the house price down. You don't have to give the answer 400...it might be better to create something that predicts the number 4, and then your answer is in the 'hundreds of thousands' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data with at least 6 data points for x and y\n",
    "xs = np.array([1,2,3,4,5,6], dtype=float)\n",
    "ys = np.array([1,1.5,2,2.5,3,3.5], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model with one layer and one neuron\n",
    "layer_1 = keras.layers.Dense(units=1, input_shape=[1])\n",
    "model = tf.keras.Sequential([layer_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model - be careful to use the correct loss for regression\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.4619\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2357\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1308\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0821\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0594\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0487\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0436\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0411\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0398\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0390\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0385\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0382\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0378\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0375\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0373\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0370\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 951us/step - loss: 0.0367\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0364\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0362\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0359\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0357\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0354\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0351\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0349\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0346\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0344\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0341\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0339\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0336\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0334\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0331\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0329\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0327\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0324\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0322\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0319\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0317\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0315\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0313\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0310\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0308\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0306\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0304\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0301\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0299\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0297\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0295\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0293\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0291\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0288\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0286\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0284\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0282\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0280\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0278\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0276\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0274\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0272\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0270\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0268\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0266\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0264\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0262\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0260\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0258\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0257\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0255\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0253\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0251\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0249\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0247\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0246\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0244\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0242\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0240\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0238\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0237\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0235\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0233\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0232\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0230\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0228\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0223\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0222\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0218\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0214\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0211\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0209\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0208\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0202\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0199\n",
      "Epoch 102/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0197\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0196\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0194\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0193\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0190\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0189\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0187\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0186\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0175\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0174\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0170\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0164\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0163\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0162\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0161\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0160\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0154\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 805us/step - loss: 0.0150\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0149\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0148\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0145\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0140\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0138\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0135\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0134\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0133\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0132\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0131\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0130\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0129\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0128\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0127\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0126\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0125\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0124\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0123\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0123\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0122\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0121\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0120\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0119\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0118\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0117\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0116\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0116\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0115\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0114\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0113\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0112\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0111\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0111\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0110\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0109\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0108\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0107\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0107\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0106\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0105\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0104\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0104\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0103\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0102\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0098\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0091\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0090\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0088\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0088\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0087\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0086\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0086\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0085\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0084\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0084\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0083\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0083\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0082\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0081\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0081\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0080\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0080\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0079\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0078\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0078\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0077\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0077\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0076\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0076\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0075\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0075\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0074\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0073\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0073\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0072\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0072\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0071\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0071\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0070\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0070\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0069\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0068\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0068\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0067\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0067\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0066\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0066\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0065\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0065\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0064\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0064\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0063\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0063\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0063\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0062\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0062\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0061\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0061\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0060\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0060\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0059\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0059\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0059\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0058\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0058\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0057\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0057\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0056\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0056\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0054\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0054\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0054\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0053\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0053\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0052\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0052\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0052\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0051\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0051\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0049\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0048\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0048\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0048\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0047\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0047\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0047\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0046\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0046\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0046\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0045\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0045\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0044\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0044\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0044\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0043\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0042\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0042\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0042\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0042\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0041\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0041\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0041\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0040\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0040\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0040\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0039\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0039\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0039\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0039\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0038\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0038\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0038\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0037\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0037\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0037\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0037\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0036\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0036\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0036\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0036\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0035\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0035\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0035\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0035\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0034\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0034\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0034\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0034\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0033\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0033\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0033\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0033\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0032\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0032\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0032\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0032\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0031\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0031\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0031\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0031\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0031\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0030\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0030\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0030\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0030\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0029\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0029\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0029\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0029\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0029\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0028\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0027\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0027\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0027\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0027\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0027\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0026\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0026\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0026\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0025\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0025\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0025\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0025\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0025\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0024\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0024\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0024\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0024\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0023\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0023\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0023\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0023\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0023\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0023\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 402/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0022\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0021\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0020\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0018\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0017\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0017\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0017\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0017\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0016\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0016\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0016\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0015\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0015\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0015\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0015\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0014\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0014\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0013\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0012\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0012\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0012\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0012\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0012\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0011\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0011\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 646us/step - loss: 0.0011\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 502/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 999us/step - loss: 0.0011\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0011\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0010\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0010\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9818e-04\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9090e-04\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.8368e-04\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7652e-04\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6940e-04\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6234e-04\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.5533e-04\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.4837e-04\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.4146e-04\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.3460e-04\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.2779e-04\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.2103e-04\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.1432e-04\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.0766e-04\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.0105e-04\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.9448e-04\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8797e-04\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8149e-04\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7507e-04\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6870e-04\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6237e-04\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5608e-04\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4985e-04\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4366e-04\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.3751e-04\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3141e-04\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2535e-04\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.1934e-04\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.1337e-04\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0744e-04\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.0156e-04\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.9572e-04\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.8992e-04\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.8417e-04\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7846e-04\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7278e-04\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6715e-04\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6156e-04\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5602e-04\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5051e-04\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.4504e-04\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3961e-04\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3422e-04\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2888e-04\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2357e-04\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1829e-04\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.1306e-04\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.0787e-04\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.0271e-04\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9759e-04\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.9251e-04\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8746e-04\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.8245e-04\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.7748e-04\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.7254e-04\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.6764e-04\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6278e-04\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.5795e-04\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.5316e-04\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4840e-04\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4368e-04\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3899e-04\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3433e-04\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.2971e-04\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.2512e-04\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.2057e-04\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1605e-04\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1156e-04\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.0710e-04\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.0268e-04\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9829e-04\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9393e-04\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.8961e-04\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.8531e-04\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8105e-04\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7681e-04\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7261e-04\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6844e-04\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.6429e-04\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6018e-04\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5610e-04\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5205e-04\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.4803e-04\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4404e-04\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.4007e-04\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3614e-04\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3223e-04\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2836e-04\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.2451e-04\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2069e-04\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1689e-04\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1312e-04\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0939e-04\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0567e-04\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.0199e-04\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.9834e-04\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9470e-04\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.9110e-04\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8752e-04\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8397e-04\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8044e-04\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.7694e-04\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.7347e-04\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7002e-04\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6659e-04\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.6320e-04\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.5982e-04\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.5647e-04\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.5314e-04\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.4984e-04\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4656e-04\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4331e-04\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4008e-04\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.3688e-04\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3369e-04\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.3053e-04\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2740e-04\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2428e-04\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2119e-04\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1812e-04\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1508e-04\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.1205e-04\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.0905e-04\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.0607e-04\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0311e-04\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.0018e-04\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.9726e-04\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9437e-04\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9149e-04\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.8864e-04\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8581e-04\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.8300e-04\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.8021e-04\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7744e-04\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7469e-04\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7196e-04\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6925e-04\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6656e-04\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.6389e-04\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6124e-04\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5860e-04\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.5599e-04\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5340e-04\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.5082e-04\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4827e-04\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4573e-04\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4321e-04\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4071e-04\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3823e-04\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3576e-04\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3332e-04\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3089e-04\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2848e-04\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2609e-04\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2371e-04\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2135e-04\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1901e-04\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1669e-04\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1438e-04\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.1209e-04\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0981e-04\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.0756e-04\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.0532e-04\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0309e-04\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0088e-04\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9869e-04\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.9652e-04\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9436e-04\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 946us/step - loss: 2.9221e-04\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9008e-04\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8797e-04\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8587e-04\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8379e-04\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8172e-04\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7967e-04\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7763e-04\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7561e-04\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7360e-04\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.7161e-04\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6963e-04\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6766e-04\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6571e-04\n",
      "Epoch 692/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 999us/step - loss: 2.6378e-04\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6186e-04\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5995e-04\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5806e-04\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5618e-04\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.5431e-04\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5246e-04\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.5062e-04\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4879e-04\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4698e-04\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4518e-04\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.4339e-04\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4162e-04\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3986e-04\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.3811e-04\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.3638e-04\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.3465e-04\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3294e-04\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.3125e-04\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2956e-04\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.2789e-04\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.2623e-04\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2458e-04\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2295e-04\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2132e-04\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1971e-04\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1811e-04\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1652e-04\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1494e-04\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1338e-04\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1182e-04\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1028e-04\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0874e-04\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0722e-04\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.0571e-04\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0421e-04\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.0273e-04\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0125e-04\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9978e-04\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9833e-04\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9688e-04\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9545e-04\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9403e-04\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9261e-04\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9121e-04\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8982e-04\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8843e-04\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.8706e-04\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8570e-04\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.8434e-04\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8300e-04\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8167e-04\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8034e-04\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7903e-04\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7773e-04\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7643e-04\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.7515e-04\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.7387e-04\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.7260e-04\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7135e-04\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7010e-04\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.6886e-04\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6763e-04\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6641e-04\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6519e-04\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6399e-04\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6280e-04\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6161e-04\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6043e-04\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5926e-04\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5810e-04\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5695e-04\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5581e-04\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5467e-04\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5355e-04\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.5243e-04\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5132e-04\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.5021e-04\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.4912e-04\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.4803e-04\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.4695e-04\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.4589e-04\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4482e-04\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4377e-04\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4272e-04\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4168e-04\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4065e-04\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3962e-04\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.3861e-04\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3759e-04\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3659e-04\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3560e-04\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3461e-04\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3363e-04\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3266e-04\n",
      "Epoch 787/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3169e-04\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3073e-04\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2978e-04\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2883e-04\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2789e-04\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2696e-04\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2604e-04\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2512e-04\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2421e-04\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2330e-04\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2240e-04\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2151e-04\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2063e-04\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1975e-04\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1888e-04\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1801e-04\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1715e-04\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1630e-04\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1545e-04\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1461e-04\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1377e-04\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1294e-04\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1212e-04\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1130e-04\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1049e-04\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0969e-04\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0889e-04\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0810e-04\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0731e-04\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0653e-04\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0575e-04\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0498e-04\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0421e-04\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0346e-04\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0270e-04\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0195e-04\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0121e-04\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0047e-04\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9741e-05\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9015e-05\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.8294e-05\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7578e-05\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.6866e-05\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6160e-05\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.5460e-05\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.4765e-05\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.4075e-05\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.3389e-05\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.2709e-05\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.2033e-05\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1363e-05\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.0697e-05\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.0036e-05\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.9380e-05\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8728e-05\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8082e-05\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7441e-05\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6803e-05\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6171e-05\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5544e-05\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4921e-05\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4302e-05\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.3687e-05\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.3078e-05\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2473e-05\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 8.1872e-05\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.1275e-05\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0683e-05\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.0095e-05\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.9512e-05\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8933e-05\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8358e-05\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7787e-05\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7219e-05\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6657e-05\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6098e-05\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5544e-05\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.4994e-05\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.4448e-05\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.3905e-05\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.3366e-05\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2832e-05\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2302e-05\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1776e-05\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1252e-05\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0733e-05\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.0217e-05\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9706e-05\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.9198e-05\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8694e-05\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8194e-05\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.7697e-05\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7204e-05\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6714e-05\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6229e-05\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1000us/step - loss: 6.5746e-05\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.5267e-05\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.4791e-05\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4319e-05\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3851e-05\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3386e-05\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2923e-05\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.2466e-05\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.2010e-05\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.1558e-05\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1110e-05\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.0665e-05\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.0222e-05\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.9784e-05\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.9349e-05\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8916e-05\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8487e-05\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.8061e-05\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.7638e-05\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.7217e-05\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6801e-05\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6387e-05\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.5976e-05\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5568e-05\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5164e-05\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4762e-05\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.4363e-05\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3966e-05\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.3574e-05\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3183e-05\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2796e-05\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.2411e-05\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.2030e-05\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1650e-05\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1274e-05\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0900e-05\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0529e-05\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0161e-05\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9796e-05\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.9432e-05\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.9073e-05\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8715e-05\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8361e-05\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8008e-05\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.7658e-05\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.7311e-05\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.6967e-05\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6624e-05\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6285e-05\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5948e-05\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.5613e-05\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5281e-05\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.4951e-05\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4623e-05\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.4298e-05\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3976e-05\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3655e-05\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3337e-05\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3022e-05\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.2708e-05\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.2396e-05\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2088e-05\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1781e-05\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1477e-05\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.1174e-05\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0875e-05\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.0577e-05\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0281e-05\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9988e-05\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9697e-05\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9407e-05\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9120e-05\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8835e-05\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8552e-05\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8271e-05\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7992e-05\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7716e-05\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7441e-05\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7169e-05\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6897e-05\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6628e-05\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6362e-05\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6097e-05\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5834e-05\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.5572e-05\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5313e-05\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5056e-05\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4801e-05\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4547e-05\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4296e-05\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.4046e-05\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.3798e-05\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3551e-05\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3307e-05\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3064e-05\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2823e-05\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2584e-05\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.2347e-05\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2111e-05\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.1877e-05\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1645e-05\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.1414e-05\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.1185e-05\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0959e-05\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0733e-05\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0509e-05\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0287e-05\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0066e-05\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9847e-05\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9629e-05\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.9414e-05\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9199e-05\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8987e-05\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8775e-05\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.8566e-05\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.8358e-05\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8151e-05\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7946e-05\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.7742e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x130a7a0af70>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with 1000 epochs\n",
    "model.fit(xs, ys, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.0075974]]\n"
     ]
    }
   ],
   "source": [
    "# predict the price for 7-bedroom house price\n",
    "print(model.predict([7.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-2 has 20 points**.\n",
    "\n",
    "In this notebook you learned how to do classification using Fashion MNIST, a data set containing items of clothing, and a similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy using `callbacks`.\n",
    "\n",
    "- **Requirements**:\n",
    "1. It should succeed in less than 10 epochs.\n",
    "2. When it reaches 99% or greater it should print out the string `\"Reached 99% accuracy so cancelling training!\"` as specified in the `myCallback` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.99):\n",
    "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# load data\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# normalize data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model - be careful about the activation functions of the hidden layer and output layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(100, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model - be careful to use the correct loss for multi-class classification, metrics should be 'accuracy'\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3885 - accuracy: 0.8913\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0962 - accuracy: 0.9707\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0643 - accuracy: 0.9807\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0463 - accuracy: 0.9855\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0368 - accuracy: 0.9878\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0316 - accuracy: 0.9897\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0273 - accuracy: 0.9914\n",
      "\n",
      "Reached 99% accuracy so cancelling training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x130a63174f0>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with 10 epochs (will stop earlier) and callbacks\n",
    "# Note: Your output should include the message: \"Reached 99% accuracy so cancelling training!\"\n",
    "# The output should also include:\n",
    "# <tensorflow.python.keras.callbacks.History at MEMORY_ADDRESS> \n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] - [Tensorflow Website](https://www.tensorflow.org/)\n",
    "- [2] - [Tensorflow Tutorials](https://www.tensorflow.org/tutorials)\n",
    "- [3] - [Hands-On ML Textbook 2nd Edition](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)\n",
    "- [4] - [DeepLearning.AI TensorFlow Developer Professional Certificate - Course-1](https://www.coursera.org/professional-certificates/tensorflow-in-practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading and Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name your notebook ```Lastname-tf-notebook.ipynb```. Submit the file using the ```tf-notebook``` link on Blackboard.\n",
    "\n",
    "- tf-notebook has a total of 30 points which will be counted towards the \"Assignment\" section of your final grade.\n",
    "\n",
    "- **RUN ALL CELLS REQUIREMENT**: You must run all cells to get the outputs and then attempt exercises. Otherwise, if any cell is not run with the correct output, your notebook gets ZERO even if you've completed the exercises.\n",
    "\n",
    "Grading will be based on \n",
    "\n",
    "  * verification of correct installation of Tensorflow\n",
    "  * error-free running of all the cells - all outputs and plots must be included - any missing output would cause the notebook to get ZERO!\n",
    "  * correct answers to the exercises - Exercise-1 [10 points], Exercise-2 [20 points]\n",
    "  \n",
    "<font color=red><b>Due Date: Tuesday April 20th, 11:59PM</b></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
